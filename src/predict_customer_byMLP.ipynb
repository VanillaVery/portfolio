{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테마파크 방문객 예측 코드\n",
    "- MLP(multi-layer perceptron)을 이용한 예측 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error,r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm \n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.font_manager as fm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"기존 데이터\"\"\"\n",
    "os.chdir(r\"디렉토리로 지정할 경로\")\n",
    "macro_raw=pd.read_csv(r\".\\input\\macrodata.csv\",encoding='euc-kr')\n",
    "\"\"\"추가되는 데이터\"\"\"\n",
    "weather=pd.read_excel(r\".\\input\\날씨.xlsx\")\n",
    "ride=pd.read_excel(r\".\\input\\놀이기구운휴정보.xlsx\")\n",
    "search=pd.read_excel(r\".\\input\\검색량.xlsx\",header=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 입장객 데이터 클렌징 및 병합 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_cleansing(admin=weather,\n",
    "                    ride=ride,  \n",
    "                    search=search, \n",
    "                    if_majeon=False, \n",
    "                    dayahead='평일',\n",
    "                    dayafter='공휴일'\n",
    "                    ):\n",
    "    admin2=admin.copy()\n",
    "    admin2.rename(columns={'시간:일자':'일시','일자:성/비성수기':'비성수기',\n",
    "                            '일자:휴일구분':'휴일구분','일자:날씨':'날씨',\n",
    "                            '날씨:최저온도':'최저온도', '날씨:최고온도':'최고온도',},inplace=True)\n",
    "    admin2.drop(admin2[admin2['일시']=='전체 결과'].index,inplace=True)\n",
    "    admin2['일시']=pd.to_datetime(admin2.일시)\n",
    "\n",
    "    # 요일 추가\n",
    "    admin2['요일숫자']=admin2['일시'].dt.weekday\n",
    "    weekday_list = ['월요일', '화요일', '수요일', '목요일', '금요일', '토요일', '일요일']\n",
    "    admin2['요일'] = admin2.apply(lambda x : weekday_list[x['요일숫자']], axis = 1)\n",
    "    admin2.drop('요일숫자',axis=1,inplace=True)\n",
    "\n",
    "    #휴일구분 전처리 추가\n",
    "\n",
    "    admin_list=[dayahead] + admin2['휴일구분'].tolist() + [dayafter] #지난 달 마지막 날과 다음 달 첫 날 병합 \n",
    "    admin2.reset_index(inplace=True)\n",
    "    admin2['index']=admin2['index']+1\n",
    "\n",
    "    def custom_holiday(휴일구분,index):\n",
    "\n",
    "        if 휴일구분 == '금요일':\n",
    "            return '평휴'\n",
    "        elif 휴일구분 == '토요일':\n",
    "            return '휴휴'\n",
    "        elif 휴일구분 =='일요일':\n",
    "            return '휴평'\n",
    "        elif 휴일구분 =='공휴일전일':\n",
    "            return '휴평'\n",
    "\n",
    "        elif 휴일구분 =='공휴일':\n",
    "            return '휴휴'\n",
    "\n",
    "        elif (휴일구분 in ['평일','공휴일전일']) & \\\n",
    "            (admin_list[index-1] in ['토요일','일요일','공휴일']) & \\\n",
    "                (admin_list[index+1] in ['토요일','일요일','공휴일']) :\n",
    "            return '휴평휴'\n",
    "\n",
    "        elif (휴일구분 not in ['평일','공휴일전일']) & \\\n",
    "            (admin_list[index-1] in ['토요일','일요일','공휴일']) & \\\n",
    "                (admin_list[index+1] in ['토요일','일요일','공휴일']) :\n",
    "            return '휴휴휴'\n",
    "        \n",
    "        else : return '평평'\n",
    "\n",
    "    admin2['휴일구분_전처리'] = admin2.apply(lambda x: custom_holiday(x['휴일구분'],x['index']),axis=1)\n",
    "\n",
    "    #날씨\n",
    "    admin2.loc[admin2['날씨'].str.contains('눈|비'),'날씨']='눈비'\n",
    "    admin2.loc[admin2['날씨'].str.contains('구름|흐림'),'날씨']='흐림'\n",
    "\n",
    "    # # 운휴정보 \n",
    "\n",
    "    ride=ride[['운휴일자','RIDE명','운휴구분']]\n",
    "    ride=ride.loc[ride['운휴구분'].isin(['일점검','정기점검','정기운휴'])]\n",
    "    ride=ride.drop_duplicates()\n",
    "    ride['count']=1\n",
    "    ride=ride.groupby(['운휴일자','RIDE명']).sum().reset_index()\n",
    "    ride2=ride.pivot(index='운휴일자',columns='RIDE명',values='count').reset_index()\n",
    "    ride2=ride2[['운휴일자','놀이기구1','놀이기구2']]\n",
    "    ride2.rename(columns={'운휴일자':'일시','놀이기구1':'놀이기구1점검','놀이기구2':'놀이기구2점검'},inplace=True)\n",
    "    ride2['일시']=pd.to_datetime(ride2.일시)\n",
    "    ride2.fillna(0)\n",
    "    ride2.rename(columns={'운휴일자':'일시'},inplace=True)\n",
    "    \n",
    "    #검색량 (lag 적용)\n",
    "    search=search.loc[1:,['날짜','테마파크','테마파크맛집','코로나']]\n",
    "    search.reset_index(drop=True, inplace=True)\n",
    "    search.rename(columns={'날짜':'일시'},inplace=True)\n",
    "    search['일시']=admin2['일시']\n",
    "    \n",
    "    #코로나 \n",
    "\n",
    "    #병합\n",
    "    admin2=pd.merge(admin2,ride2,how='left',on='일시')\n",
    "    admin2=pd.merge(admin2,search,how='left',on='일시')\n",
    "    admin2.drop(columns=['index','휴일구분'],axis=1,inplace=True)\n",
    "    admin2=admin2.fillna(0)\n",
    "\n",
    "    admin2['년']=admin2['일시'].dt.year\n",
    "    admin2['월']=admin2['일시'].dt.month\n",
    "    admin2['covid']=0\n",
    "\n",
    "    if type(if_majeon)==pd.DataFrame:\n",
    "        if_majeon.rename(columns={'유형별 입장객분류':'일시'},inplace=True)\n",
    "        if_majeon = if_majeon.iloc[:-1,[0,5]] #전체 결과, 타 경로 삭제 \n",
    "        if_majeon['일시']=pd.to_datetime(if_majeon['일시'])\n",
    "        admin2['전체입장객']=if_majeon['전체 결과'] #        \n",
    "    else: \n",
    "        admin2['전체입장객']=-999\n",
    "    return admin2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"함수 실행 결과\"\"\"\n",
    "macro_cleansing(admin=weather, \n",
    "                    ride=ride, \n",
    "                    search=search, \n",
    "                    if_majeon=False, # 학습용: majeon, 예측용: False \n",
    "                    dayahead='평일', #수기로 입력\n",
    "                    dayafter='공휴일' #수기로 입력\n",
    "                    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### macro 데이터와 병합하여 훈련데이터 완성\n",
    "- 위의 함수를 사용하여 만들어진 n월 데이터를 macro 데이터와 concat 하여 훈련 데이터 완성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"위의 통합데이터 macro와 병합하여 사용\"\"\"\n",
    "\n",
    "\"\"\"#사용예시\"\"\"\n",
    "data_2212 = macro_cleansing(admin=weather,\n",
    "                            ride=ride, \n",
    "                            search=search, \n",
    "                            if_majeon=False,\n",
    "                            dayahead='평일', \n",
    "                            dayafter='공휴일')\n",
    "macro_raw = pd.concat([macro_raw,data_2212])\n",
    "\n",
    "\n",
    "# 해당 월이 병합된 macro data 완성 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 데이터 예측 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_total_visitor(macro_raw,year,month,validation=False): #기본값\n",
    "    \n",
    "    macro=macro_raw.copy()\n",
    "    \n",
    "    #covid=1인 기간 없애기\n",
    "    macro.drop(macro[macro['covid']==1].index,inplace=True)\n",
    "    macro.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    #train,test 분리\n",
    "    test = macro[(macro['년']==year)&(macro['월']==month)].index\n",
    "    train = list(set(macro.index)-set(test))\n",
    "\n",
    "    macro['전체입장객']=macro['전체입장객'].astype(str)\n",
    "    macro['전체입장객']=macro['전체입장객'].apply(lambda x: float(x.replace(',',''))) #쉼표 삭제 \n",
    "\n",
    "    macro['전체입장객']=macro['전체입장객'].astype(float)\n",
    "    #train only\n",
    "    macro.loc[train,'전체입장객']=macro.loc[train,'전체입장객'].apply(lambda x: 25000 if x>=25000 else x)\n",
    "    macro['전체입장객']=macro['전체입장객'].apply(lambda x: x/100)\n",
    "    \n",
    "    macro.loc[macro['테마파크']>=70000,'테마파크']=70000\n",
    "    macro.loc[macro['코로나']>=3000000,'코로나']=3000000\n",
    "\n",
    "    # 전체입장객 로그 취하기\n",
    "    macro['log_전체입장객']=np.log(macro['전체입장객'])\n",
    "    macro.drop(columns='전체입장객',axis=1, inplace=True)\n",
    "\n",
    "    # 테마파크 검색량 로그 취하기\n",
    "    macro['log_테마파크']=np.log(macro['테마파크'])\n",
    "    macro.drop(columns='테마파크',axis=1, inplace=True)\n",
    "\n",
    "    # 테마파크맛집 검색량 로그 취하기\n",
    "    macro['log_테마파크맛집']=np.log(macro['테마파크맛집'])\n",
    "    macro.drop(columns='테마파크맛집',axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    #%% 모델 학습 및 테스트\n",
    "    SEED = 42\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "    tf.random.set_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"명목변수 dummy & 데이터 형태 변형\"\"\"\n",
    "    dummy_macro=pd.get_dummies(\n",
    "                            macro.drop(columns=['일시','log_전체입장객', '년']),\n",
    "                            columns=['월','비성수기','요일','휴일구분_전처리','날씨'])\n",
    "\n",
    "    \"\"\"연속변수 scaling\"\"\"\n",
    "\n",
    "    x_train=dummy_macro.iloc[train]\n",
    "    x_test=dummy_macro.iloc[test]\n",
    "\n",
    "    continuous = ['최저온도', '최고온도', '코로나', 'log_테마파크', 'log_테마파크맛집']\n",
    "    mean = x_train[continuous].mean()\n",
    "    std = x_train[continuous].std()\n",
    "    x_train[continuous] = (x_train[continuous] - mean) / std\n",
    "    x_test[continuous] = (x_test[continuous] - mean) / std\n",
    "\n",
    "\n",
    "    np_x_train=x_train.to_numpy()\n",
    "    np_x_test=x_test.to_numpy()\n",
    "    np_y_train=macro.loc[train,'log_전체입장객'].to_numpy()\n",
    "    np_y_test=macro.loc[test,'log_전체입장객'].to_numpy()\n",
    "\n",
    "    \"\"\"# 모델 정의 \"\"\"\n",
    "    model=tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=8,activation='tanh',input_shape=(np_x_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(units=1,activation='elu')\n",
    "    ])\n",
    "\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "    mae_plot = []\n",
    "    mape_plot = []\n",
    "    for iteration in range(1000):\n",
    "        idx = np.random.choice(range(len(train)), 256, replace=False) # batch\n",
    "        x = np_x_train[idx]\n",
    "        y = np_y_train[idx][:, tf.newaxis] \n",
    "        x = tf.cast(x, tf.float32)\n",
    "        y = tf.cast(y, tf.float32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 1. 예측 (prediction)\n",
    "            predictions = model(x)\n",
    "            # 2. Loss 계산\n",
    "            loss = tf.reduce_mean(tf.abs(predictions - y))\n",
    "        \n",
    "        mape = tf.stop_gradient(tf.reduce_mean(tf.abs((tf.exp(predictions) - tf.math.exp(y)) / tf.math.exp(y))))\n",
    "        if tf.math.is_inf(mape):\n",
    "            break\n",
    "            \n",
    "        # 3. 그라디언트(gradients) 계산\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "        # 4. 오차역전파(Backpropagation) - weight 업데이트\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        if iteration % 10 == 0:\n",
    "            print('Iteration: {:02d}, Loss: {:.4f}, MAPE: {:.4f}%'.format(iteration, loss, mape * 100))\n",
    "        mae_plot.append(loss)\n",
    "        mape_plot.append(mape)\n",
    "\n",
    "    # test\n",
    "    x = np_x_test\n",
    "    y = np_y_test\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    y = tf.cast(y, tf.float32)\n",
    "\n",
    "    # 예측값 저장\n",
    "    yhat = model(x)\n",
    "\n",
    "    if validation:\n",
    "        #검증용  \n",
    "        real = np.array([np.sum((tf.exp(y) * 100))])\n",
    "        predict = np.array([np.sum((tf.exp(yhat) * 100))])\n",
    "        accuracy = np.array(1-abs(real-predict)/real)\n",
    "        years=np.array([year],dtype='float32')\n",
    "        months=np.array([month],dtype='float32')\n",
    "        # days=np.array([i+1 for i in range(len(predict))])[:, None]\n",
    "        # 일별 전체입장객 예측치 및 정확도 \n",
    "        tmp=np.concatenate([years,months,real,predict,accuracy],axis=0)\n",
    "        \n",
    "        return pd.DataFrame([tmp],columns=['년','월','실제값','예측치','정확도'])\n",
    "\n",
    "    else: \n",
    "        # 예측용\n",
    "        predict = np.array((tf.exp(yhat) * 100))\n",
    "        years=np.array([year for i in range(len(predict))])[:, None]\n",
    "        months=np.array([month for i in range(len(predict))])[:, None]\n",
    "        days=np.array([i+1 for i in range(len(predict))])[:, None]\n",
    "        # 일별 전체입장객 예측치 및 정확도 \n",
    "        tmp=np.concatenate([years,months,days,predict],axis=1)\n",
    "\n",
    "        return pd.DataFrame(tmp,columns=['년','월','일','예측치'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측용 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 00, Loss: 4.0472, MAPE: 97.6774%\n",
      "Iteration: 10, Loss: 3.9529, MAPE: 97.3991%\n",
      "Iteration: 20, Loss: 3.7777, MAPE: 96.7241%\n",
      "Iteration: 30, Loss: 3.6076, MAPE: 95.9698%\n",
      "Iteration: 40, Loss: 3.4643, MAPE: 95.5522%\n",
      "Iteration: 50, Loss: 3.2427, MAPE: 94.2405%\n",
      "Iteration: 60, Loss: 3.0190, MAPE: 92.9043%\n",
      "Iteration: 70, Loss: 2.7801, MAPE: 91.3426%\n",
      "Iteration: 80, Loss: 2.5682, MAPE: 89.1404%\n",
      "Iteration: 90, Loss: 2.2011, MAPE: 85.2087%\n",
      "Iteration: 100, Loss: 2.1361, MAPE: 84.0312%\n",
      "Iteration: 110, Loss: 1.7172, MAPE: 76.8936%\n",
      "Iteration: 120, Loss: 1.5477, MAPE: 72.7968%\n",
      "Iteration: 130, Loss: 1.3248, MAPE: 67.5761%\n",
      "Iteration: 140, Loss: 1.2509, MAPE: 65.2734%\n",
      "Iteration: 150, Loss: 0.9340, MAPE: 54.7971%\n",
      "Iteration: 160, Loss: 0.8243, MAPE: 50.2565%\n",
      "Iteration: 170, Loss: 0.6687, MAPE: 46.3882%\n",
      "Iteration: 180, Loss: 0.5997, MAPE: 42.2914%\n",
      "Iteration: 190, Loss: 0.4894, MAPE: 41.4336%\n",
      "Iteration: 200, Loss: 0.4371, MAPE: 39.6958%\n",
      "Iteration: 210, Loss: 0.4220, MAPE: 39.1742%\n",
      "Iteration: 220, Loss: 0.4293, MAPE: 40.8572%\n",
      "Iteration: 230, Loss: 0.3922, MAPE: 37.9161%\n",
      "Iteration: 240, Loss: 0.4244, MAPE: 41.8705%\n",
      "Iteration: 250, Loss: 0.3858, MAPE: 37.9049%\n",
      "Iteration: 260, Loss: 0.3632, MAPE: 36.5905%\n",
      "Iteration: 270, Loss: 0.3219, MAPE: 33.7632%\n",
      "Iteration: 280, Loss: 0.3290, MAPE: 32.3076%\n",
      "Iteration: 290, Loss: 0.3264, MAPE: 33.5431%\n",
      "Iteration: 300, Loss: 0.3197, MAPE: 32.0082%\n",
      "Iteration: 310, Loss: 0.2947, MAPE: 29.4134%\n",
      "Iteration: 320, Loss: 0.3017, MAPE: 29.5634%\n",
      "Iteration: 330, Loss: 0.2698, MAPE: 27.2228%\n",
      "Iteration: 340, Loss: 0.2997, MAPE: 29.9865%\n",
      "Iteration: 350, Loss: 0.2573, MAPE: 24.3232%\n",
      "Iteration: 360, Loss: 0.2687, MAPE: 26.0859%\n",
      "Iteration: 370, Loss: 0.2606, MAPE: 25.0675%\n",
      "Iteration: 380, Loss: 0.2392, MAPE: 23.2565%\n",
      "Iteration: 390, Loss: 0.2620, MAPE: 25.3593%\n",
      "Iteration: 400, Loss: 0.2671, MAPE: 25.6006%\n",
      "Iteration: 410, Loss: 0.2327, MAPE: 22.0837%\n",
      "Iteration: 420, Loss: 0.2221, MAPE: 21.5793%\n",
      "Iteration: 430, Loss: 0.2402, MAPE: 23.0681%\n",
      "Iteration: 440, Loss: 0.2207, MAPE: 21.2227%\n",
      "Iteration: 450, Loss: 0.2286, MAPE: 22.3574%\n",
      "Iteration: 460, Loss: 0.2299, MAPE: 22.8437%\n",
      "Iteration: 470, Loss: 0.2548, MAPE: 23.1021%\n",
      "Iteration: 480, Loss: 0.2345, MAPE: 23.4934%\n",
      "Iteration: 490, Loss: 0.2225, MAPE: 21.9798%\n",
      "Iteration: 500, Loss: 0.2383, MAPE: 22.7161%\n",
      "Iteration: 510, Loss: 0.2304, MAPE: 21.7545%\n",
      "Iteration: 520, Loss: 0.2321, MAPE: 21.9741%\n",
      "Iteration: 530, Loss: 0.2184, MAPE: 20.8920%\n",
      "Iteration: 540, Loss: 0.1876, MAPE: 18.1012%\n",
      "Iteration: 550, Loss: 0.2214, MAPE: 21.9497%\n",
      "Iteration: 560, Loss: 0.2231, MAPE: 21.3632%\n",
      "Iteration: 570, Loss: 0.2275, MAPE: 21.6562%\n",
      "Iteration: 580, Loss: 0.2089, MAPE: 19.7004%\n",
      "Iteration: 590, Loss: 0.2231, MAPE: 21.0111%\n",
      "Iteration: 600, Loss: 0.2138, MAPE: 20.4402%\n",
      "Iteration: 610, Loss: 0.2290, MAPE: 21.8828%\n",
      "Iteration: 620, Loss: 0.2108, MAPE: 20.1419%\n",
      "Iteration: 630, Loss: 0.1952, MAPE: 18.7037%\n",
      "Iteration: 640, Loss: 0.2142, MAPE: 20.8325%\n",
      "Iteration: 650, Loss: 0.1968, MAPE: 19.0900%\n",
      "Iteration: 660, Loss: 0.2176, MAPE: 19.7401%\n",
      "Iteration: 670, Loss: 0.2031, MAPE: 19.5329%\n",
      "Iteration: 680, Loss: 0.1877, MAPE: 18.4555%\n",
      "Iteration: 690, Loss: 0.2253, MAPE: 21.5570%\n",
      "Iteration: 700, Loss: 0.1979, MAPE: 19.3532%\n",
      "Iteration: 710, Loss: 0.2058, MAPE: 20.2559%\n",
      "Iteration: 720, Loss: 0.2071, MAPE: 19.3355%\n",
      "Iteration: 730, Loss: 0.1758, MAPE: 16.7563%\n",
      "Iteration: 740, Loss: 0.2117, MAPE: 19.9394%\n",
      "Iteration: 750, Loss: 0.1985, MAPE: 19.2461%\n",
      "Iteration: 760, Loss: 0.2165, MAPE: 20.8257%\n",
      "Iteration: 770, Loss: 0.2069, MAPE: 19.4581%\n",
      "Iteration: 780, Loss: 0.1891, MAPE: 18.5479%\n",
      "Iteration: 790, Loss: 0.1905, MAPE: 17.8891%\n",
      "Iteration: 800, Loss: 0.2013, MAPE: 19.1902%\n",
      "Iteration: 810, Loss: 0.2059, MAPE: 20.4881%\n",
      "Iteration: 820, Loss: 0.1885, MAPE: 18.0098%\n",
      "Iteration: 830, Loss: 0.1887, MAPE: 18.7712%\n",
      "Iteration: 840, Loss: 0.1900, MAPE: 18.5825%\n",
      "Iteration: 850, Loss: 0.1856, MAPE: 17.9885%\n",
      "Iteration: 860, Loss: 0.1848, MAPE: 18.3234%\n",
      "Iteration: 870, Loss: 0.1770, MAPE: 17.3290%\n",
      "Iteration: 880, Loss: 0.1842, MAPE: 17.7962%\n",
      "Iteration: 890, Loss: 0.1836, MAPE: 17.7457%\n",
      "Iteration: 900, Loss: 0.1948, MAPE: 18.7071%\n",
      "Iteration: 910, Loss: 0.1980, MAPE: 19.0571%\n",
      "Iteration: 920, Loss: 0.1955, MAPE: 18.5823%\n",
      "Iteration: 930, Loss: 0.1793, MAPE: 17.4919%\n",
      "Iteration: 940, Loss: 0.1878, MAPE: 18.0361%\n",
      "Iteration: 950, Loss: 0.1816, MAPE: 17.5770%\n",
      "Iteration: 960, Loss: 0.1874, MAPE: 19.1076%\n",
      "Iteration: 970, Loss: 0.1955, MAPE: 18.0738%\n",
      "Iteration: 980, Loss: 0.1762, MAPE: 17.3416%\n",
      "Iteration: 990, Loss: 0.1815, MAPE: 17.8387%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>년</th>\n",
       "      <th>월</th>\n",
       "      <th>일</th>\n",
       "      <th>예측치</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15066.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17291.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18433.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13500.967773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8788.854492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8846.322266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8917.715820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8747.450195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11765.447266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14426.413086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13566.249023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9981.654297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8998.662109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9611.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9422.169922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10578.985352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16094.010742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13621.858398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8575.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8916.831055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8617.814453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9285.589844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11890.417969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16325.401367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11887.362305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9755.098633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8673.679688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9026.268555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9036.026367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11678.064453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16090.803711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         년     월     일           예측치\n",
       "0   2022.0  12.0   1.0  15066.099609\n",
       "1   2022.0  12.0   2.0  17291.500000\n",
       "2   2022.0  12.0   3.0  18433.687500\n",
       "3   2022.0  12.0   4.0  13500.967773\n",
       "4   2022.0  12.0   5.0   8788.854492\n",
       "5   2022.0  12.0   6.0   8846.322266\n",
       "6   2022.0  12.0   7.0   8917.715820\n",
       "7   2022.0  12.0   8.0   8747.450195\n",
       "8   2022.0  12.0   9.0  11765.447266\n",
       "9   2022.0  12.0  10.0  14426.413086\n",
       "10  2022.0  12.0  11.0  13566.249023\n",
       "11  2022.0  12.0  12.0   9981.654297\n",
       "12  2022.0  12.0  13.0   8998.662109\n",
       "13  2022.0  12.0  14.0   9611.117188\n",
       "14  2022.0  12.0  15.0   9422.169922\n",
       "15  2022.0  12.0  16.0  10578.985352\n",
       "16  2022.0  12.0  17.0  16094.010742\n",
       "17  2022.0  12.0  18.0  13621.858398\n",
       "18  2022.0  12.0  19.0   8575.007812\n",
       "19  2022.0  12.0  20.0   8916.831055\n",
       "20  2022.0  12.0  21.0   8617.814453\n",
       "21  2022.0  12.0  22.0   9285.589844\n",
       "22  2022.0  12.0  23.0  11890.417969\n",
       "23  2022.0  12.0  24.0  16325.401367\n",
       "24  2022.0  12.0  25.0  11887.362305\n",
       "25  2022.0  12.0  26.0   9755.098633\n",
       "26  2022.0  12.0  27.0   8673.679688\n",
       "27  2022.0  12.0  28.0   9026.268555\n",
       "28  2022.0  12.0  29.0   9036.026367\n",
       "29  2022.0  12.0  30.0  11678.064453\n",
       "30  2022.0  12.0  31.0  16090.803711"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction=predict_total_visitor(macro_raw=macro_raw,year=2022,month=12,validation=False)\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ellieyj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8504bd1aecc317fca006a17368d191d48192223a4de836fecf71ff2e0cd6f44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
